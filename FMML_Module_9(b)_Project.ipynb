{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aswinimedisetti28/Fmmllabassiments/blob/main/FMML_Module_9(b)_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 9(b): Convolutional Neural Networks Project\n",
        "\n",
        "## Module coordinator: Kushagra Agarwal\n",
        "\n"
      ],
      "metadata": {
        "id": "LF8nIY5yEw3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://hub.packtpub.com/wp-content/uploads/2018/04/iStock-851960058-696x464.jpg\" width=850px/>"
      ],
      "metadata": {
        "id": "2EIAlTLKPQj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, you will understand how you can perform emotion recognition using CNNs in a step-by-step manner. To make your task easier, we provide you the starter code for the project. It is expected that you should try to understand the project statement properly and perform the tasks in sequence. We will be using Pytorch framework for the implementation. You need to fill in the missing code parts to achieve a particular task. At the end, you will have a basic implementation ready for an emotion detection application.\n",
        "\n",
        "Basic steps involved in Emotion Recognition:\n",
        "- Face detection\n",
        "- Building classifier\n",
        "- Classifying emotions\n",
        "\n",
        "We will use a popular FER2013 dataset for this project."
      ],
      "metadata": {
        "id": "jL7zt_6bPNXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Explore the dataset\n",
        "The dataset contains 48 x 48 grayscale facial images of faces.The faces have been automatically registered so that the face is more or less centred and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression into one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)."
      ],
      "metadata": {
        "id": "hpBbqZ39FF_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.researchgate.net/profile/Chaudhary-Aqdus/publication/349055345/figure/fig3/AS:987834383085568@1612529478973/FER-2013-sample-images-for-facial-emotion-recognition.jpg\" width=650px/>"
      ],
      "metadata": {
        "id": "c9UGeEuTPr4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "kXy7bFuIFPA_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh_RSwSCEnrZ"
      },
      "outputs": [],
      "source": [
        "# We have imported the necessary packages here. Feel free to import anything more you need!\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import dlib\n",
        "import cv2\n",
        "!pip install torch torchvision\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and load dataset"
      ],
      "metadata": {
        "id": "o9BUAlmDFeEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1YrNrok2Z1udWWIpejXIdLk7duUq87s0N\n",
        "!unzip fer2013.csv.zip"
      ],
      "metadata": {
        "id": "iaPP5dHSFWgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset csv using pandas package. It displays the data in tabular form\n",
        "emotion_data = pd.read_csv('./fer2013.csv')\n",
        "print(emotion_data)"
      ],
      "metadata": {
        "id": "9LOSUCeZFglQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class dictionary for dataset\n",
        "classes = {0:\"Angry\", 1:\"Disgust\", 2:\"Fear\", 3:\"Happy\", 4:\"Sad\", 5:\"Surprise\", 6:\"Neutral\"}"
      ],
      "metadata": {
        "id": "petzLP_HFjNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize a few images from dataset"
      ],
      "metadata": {
        "id": "nyWdEqz3FpCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12,4))\n",
        "for i in range(10):\n",
        "  ax = plt.subplot(2,5,i+1)\n",
        "  # This is how we access ith row in 'pixels' column in the dataset table\n",
        "  img = emotion_data.iloc[i]['pixels'].split(' ') # Converting into array of ints\n",
        "  img = np.array(img).astype(int)\n",
        "\n",
        "  # Labels for our dataset\n",
        "  label = int(emotion_data.iloc[i]['emotion'])\n",
        "  ax.imshow(img.reshape((48,48)), cmap='gray')\n",
        "  ax.set_title(classes[label])\n",
        "  ax.set_axis_off()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nnuUwMwaFoWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names, counts = np.unique(emotion_data['Usage'].to_numpy(), return_counts=True)\n",
        "print('Number of samples in {} = {}'.format(names[0], counts[0])) #testset\n",
        "print('Number of samples in {} = {}'.format(names[1], counts[1])) #valset\n",
        "print('Number of samples in {} = {}'.format(names[2], counts[2])) #trainset"
      ],
      "metadata": {
        "id": "jOYEnyhqFquh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribution of class labels"
      ],
      "metadata": {
        "id": "exip5hjXF9uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot bar chart showing number of samples per class in the train set\n",
        "temp_train = emotion_data.loc[emotion_data['Usage'] == 'Training']\n",
        "df_temp_train = temp_train.sort_values(by = \"emotion\", inplace = False)\n",
        "fig = plt.figure(figsize = (7, 5))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_title(\"Count of each Emotion in Train Data\", fontsize = 20)\n",
        "sns.countplot(x = \"emotion\", data = df_temp_train)\n",
        "plt.grid()\n",
        "for i in ax.patches:\n",
        "    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 20, color = \"grey\")\n",
        "plt.xlabel(\"Classes\"+ str(classes))\n",
        "plt.ylabel(\"Count\", fontsize = 15)\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.xticks(rotation = 40)\n",
        "plt.show()\n",
        "\n",
        "### Task: Similarly, write the code below to plot the charts for remaining two sets also."
      ],
      "metadata": {
        "id": "9fu3LIjCFzva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the imbalance in the data through above graphs."
      ],
      "metadata": {
        "id": "RgyJVkVeGJiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Face detection: Many applications involving facial images as input data require face detection in the pipeline at this step. Here, we localise the face in the given image removing the irrelevant parts, making the face centered and occupying most of the part in the image. As mentioned earlier, our dataset already has more or less centered faces, so we will skip this step for now but when using some other dataset or using your own images (eg. from webcam) as you will do later, you can do this step to get a proper cropped face from the image."
      ],
      "metadata": {
        "id": "tGzXGpFgHcED"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKqBdliUNhiS"
      },
      "source": [
        "## Task 2: Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QmcaX7yNsMf"
      },
      "source": [
        "### Creating train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eBsC7i2-NTI"
      },
      "source": [
        "X_train, y_train = [], []\n",
        "X_val, y_val = [], []\n",
        "X_test, y_test = [], []\n",
        "\n",
        "for index, row in emotion_data.iterrows():\n",
        "  k = row['pixels'].split(\" \")\n",
        "\n",
        "  if row['Usage'] == 'Training':\n",
        "    X_train.append(np.array(k))\n",
        "    y_train.append(row['emotion'])\n",
        "\n",
        "  # Similarly write the conditions for test and val splits here\n",
        "  ###### YOUR CODE HERE  ######\n",
        "\n",
        "\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_val, y_val = np.array(X_val), np.array(y_val)\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "print('Training set shape: ', X_train.shape, y_train.shape)\n",
        "print('Validation set shape: ', X_val.shape, y_val.shape)\n",
        "print('Testing set shape: ', X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pvWe82a_KIO"
      },
      "source": [
        "# To get data between 0 and 1\n",
        "X_train = X_train.astype(float) / 255.\n",
        "X_test = X_test.astype(float) / 255.\n",
        "X_val = X_val.astype(float) / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_A4SIWRYvVd"
      },
      "source": [
        "We will define a dataset wrapper over Pytorch Dataset class which takes in the numpy arrays we created and returns a sample with required preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkU6ZNlIl_uw"
      },
      "source": [
        "class Fer2013Dataset(Dataset):\n",
        "  def __init__(self, x, y, transforms=None):\n",
        "    self.x = x.reshape((-1, 48, 48))\n",
        "    self.y = y\n",
        "    self.transforms= transforms\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img, y = self.x[index], self.y[index]\n",
        "\n",
        "    if self.transforms is not None:\n",
        "        img = self.transforms(img)\n",
        "    return img, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfyIAW5tYZXf"
      },
      "source": [
        "batch_size=32\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Create tensor dataset from above tensors\n",
        "train_dataset = Fer2013Dataset(X_train, y_train, transforms=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "val_dataset = Fer2013Dataset(X_val, y_val, transforms=transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "test_dataset = Fer2013Dataset(X_test, y_test, transforms=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVeKhcxOaOi-"
      },
      "source": [
        "## Task 3: Building a CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-fjjr6UZ1sc"
      },
      "source": [
        "# Define your CNN architecture here\n",
        "# To start with, let's say you can create a model with 4 relu-activated convs,\n",
        "# each followed by a pooling layer. Then, you can add 2-3 fully connected layers\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        #### YOUR CODE HERE  ####\n",
        "\n",
        "    def forward(self,x):\n",
        "        #### YOUR CODE HERE  ####\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh2oKndcbVKa"
      },
      "source": [
        "# Device (CPU/GPU)\n",
        "device = 'cpu' #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the CNN\n",
        "model = Net().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training/Testing functions"
      ],
      "metadata": {
        "id": "JffKONlJKQXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, loss_func, optimizer, num_epochs):\n",
        "\n",
        "  # Training mode\n",
        "  model.train()\n",
        "\n",
        "  train_losses = []\n",
        "  train_acc = []\n",
        "\n",
        "  # Train the model\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "      # clear gradients for this training step\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      output = model(images)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = loss_func(output, labels)\n",
        "\n",
        "      # Backpropagation, compute gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # Apply gradients\n",
        "      optimizer.step()\n",
        "\n",
        "      # Running loss\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # indices of max probabilities\n",
        "      _, preds = torch.max(output, dim=1)\n",
        "\n",
        "      # Calculate number of correct predictions\n",
        "      correct = (preds.float() == labels).sum()\n",
        "      running_acc += correct\n",
        "\n",
        "      # Average loss and acc values\n",
        "      epoch_loss = running_loss / len(train_loader.dataset)\n",
        "      epoch_acc = running_acc / len(train_loader.dataset)\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    print ('Epoch {}/{}, Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch + 1, num_epochs, epoch_loss, epoch_acc*100))\n",
        "\n",
        "  return train_losses, train_acc"
      ],
      "metadata": {
        "id": "S6BE_5aPF_eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, testloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # Deactivate autograd engine (don't compute grads since we're not training)\n",
        "  with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # Calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # The class with the highest value is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network: %d %%' % (\n",
        "      100 * correct / total))"
      ],
      "metadata": {
        "id": "w2BCd3JOJHnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcBGf4oZdRYD"
      },
      "source": [
        "## Task 4: Training & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skrXHHTlfDNj"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKRqaFn6dU3t"
      },
      "source": [
        "if \"MyModel\" in globals():\n",
        "    print(\"MyModel class is defined\")\n",
        "else:\n",
        "    print(\"MyModel class is not defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sys.modules)"
      ],
      "metadata": {
        "id": "3LwG_s1uaTmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if '__name__' in sys.modules:\n",
        "    print(\"The '__name__' attribute exists in sys.modules.\")\n",
        "else:\n",
        "    print(\"The '__name__' attribute does not exist in sys.modules.\")"
      ],
      "metadata": {
        "id": "q3NG52Abar0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if '__name__' in sys.modules:\n",
        "    if 'history' in sys.modules[__name__].__dict__:\n",
        "        print(\"The 'history' variable is defined in the '__name__' module.\")\n",
        "    else:\n",
        "        print(\"The 'history' variable is not defined in the '__name__' module.\")"
      ],
      "metadata": {
        "id": "-bRnpaQ_auDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the history variable\n",
        "history = {'loss': [0.1, 0.2, 0.3], 'accuracy': [0.8, 0.9, 1.0]}\n",
        "\n",
        "# Plot loss and accuracy curves\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "ax = fig.add_subplot(1,2, 1)\n",
        "ax.plot(np.arange(1,len(history['loss'])+1),history['loss'])\n",
        "plt.xlabel('Loss')\n",
        "plt.ylabel('Epochs')\n",
        "\n",
        "ax = fig.add_subplot(1,2, 2)\n",
        "ax.plot(np.arange(1,len(history['accuracy'])+1),history['accuracy'])\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NG1wb_bFKvv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIc4E7dDd-RJ"
      },
      "source": [
        "### Evaluate your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofh6NYJe_AfQ"
      },
      "source": [
        "# Visualize top K predictions\n",
        "def visualize_prediction(image, model, k=3):\n",
        "  model.eval()\n",
        "\n",
        "  preds = model(image.unsqueeze(1).float())\n",
        "\n",
        "  topk = torch.topk(preds, k, dim=1)\n",
        "  topk = topk.indices.numpy()\n",
        "  print('Top {} Predictions'.format(k))\n",
        "  for i in range(3):\n",
        "    print('{}) {}'.format(i+1, classes[topk[0][i]]))\n",
        "\n",
        "  plt.imshow(image[0].numpy(), cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HexADTCBiFU"
      },
      "source": [
        "# Visualize top K predictions\n",
        "def visualize_prediction(image, model, k=3):\n",
        "  model.eval()\n",
        "\n",
        "  preds = model(image.unsqueeze(1).float())\n",
        "\n",
        "  topk = torch.topk(preds, k, dim=1)\n",
        "  topk = topk.indices.numpy()\n",
        "  print('Top {} Predictions'.format(k))\n",
        "  for i in range(3):\n",
        "    print('{}) {}'.format(i+1, classes[topk[0][i]]))\n",
        "\n",
        "  plt.imshow(image[0].numpy(), cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_dataset))"
      ],
      "metadata": {
        "id": "XguRHLg8b2fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(test_dataset))\n"
      ],
      "metadata": {
        "id": "AfuQUCdBbuWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BONUS TASK\n",
        "\n",
        "### How can you improve the performance of your model given that the number of datapoints is fixed?\n",
        "\n",
        "Hint: A very simple fix (discussed in Lab 2) is to use a pretrained CNN model. The pretrained model could be trained on any dataset (eg Imagenet) and the first few layers of the same can be directly used for this task.\n",
        "\n",
        "### You are encouraged to try out different pretrained models like ResNet/VGG/AlexNet and see how the performance improves. Do all the models result in similar accuracy?"
      ],
      "metadata": {
        "id": "FwAjEp34QCsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "When the number of data points is fixed, there are several strategies to improve the performance of the model. One of them is using Pretrained Models."
      ],
      "metadata": {
        "id": "0tCGs6rNWpVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##bonus task\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "# Check whether GPU is available or not if availaible then set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define transformations to apply to the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "UdaMhZh6Ws5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 dataset\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the dataloaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n",
        "\n",
        "# Load pre-trained ResNet model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify the model's architecture for CIFAR-10 classification\n",
        "num_classes = 10\n",
        "model.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "# Move the model to the device (CPU or GPU)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100 * correct / total\n",
        "\n",
        "    # Evaluation on the test set\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * test_correct / test_total\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}]: \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
        "          f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sopI07UMdSSC",
        "outputId": "d861c0ce-795c-4bd9-e147-0840f6040186"
      },
      "execution_count": 26,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 99821850.34it/s] \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 166MB/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3]: Train Loss: 0.9587, Train Accuracy: 67.91%, Test Accuracy: 72.20%\n",
            "Epoch [2/3]: Train Loss: 0.6503, Train Accuracy: 78.15%, Test Accuracy: 75.60%\n",
            "Epoch [3/3]: Train Loss: 0.5186, Train Accuracy: 82.40%, Test Accuracy: 78.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The models results in little bit different accuracy."
      ],
      "metadata": {
        "id": "M2TIIHcUdbH9"
      }
    }
  ]
}